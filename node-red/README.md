# Node-RED 目录\n\n此目录用于存放 Node-RED 的 flows 与相关配置。\n\n包含文件（本次提交）：\n- flows/takt_collect_v5_local.json  - 极简节拍采集流程 (V5 - 本地时间)\n- flows/takt_api_v5.json           - 提供 /api/takt-logs 的 API 流程 (V5)\n\n使用说明：\n1. 将对应的 JSON 文件导入到 Node-RED 中 (菜单 → 导入)。\n2. 在生产环境请检查并更新数据库连接配置 (postgreSQLConfig)，不要在公开仓库中保留明文密码。\n3. credentials.json 等敏感文件请使用环境变量或密钥管理方案。\n

2025-11-25发现BUG:

你发现我们现在的 V5 逻辑，**无法区分“生产节拍”和“隔夜停机”**。
我来帮你完整地描述一遍你发现的这个“灾难性”场景：
1.  **周一下午 5:00（下班前）：**
    * “B线-工序A” 生产了最后一个产品，触发了信号。
    * Node-RED 的 V5 `function` 节点执行。
    * `flow.set("last_time_ST-01", "周一 17:00:00")`。
    * 这个“周一 17:00:00”的时间戳，被**永久地**保存在了 Node-RED 的“流程内存”（Flow Context）里。
2.  **设备断电，工人下班：**
    * 产线设备断电了。
    * 但是，Node-RED 是一个**服务器**，它**没有**断电，它还在 7x24 小时运行。
    * 所以，那个 "周一 17:00:00" 的时间戳，**一直“挂”在内存里**，它没有被清除。
3.  **周二早上 8:00（上班开机）：**
    * 工人给“B线-工序A”上电，生产了当天的**第一个**产品，触发了信号。
    * Node-RED 的 V5 `function` 节点被**再次**触发。
4.  **V5 逻辑执行（“灾难”发生）：**
    * `now` 变量被设为: "周二 08:00:00"。
    * `lastTimeStr = flow.get("last_time_ST-01")`。
    * Node-RED 成功地从内存里取出了 "周一 17:00:00"。
    * `if (lastTimeStr)` 这个判断为 **`true`**！
    * `interval` (节拍) 被计算为： "周二 08:00:00" **减去** "周一 17:00:00" = 15个小时（**54,000 秒**）。
    * 数据库 `takt_logs` 被写入一条新数据：`('ST-01', ..., '周二 08:00:00', '周一 17:00:00', 54000.0)`。
5.  **你“不能接受”的后果：**
    * 你不能接受，因为这个 **54,000 秒** 的“节拍”是**毫无意义的“脏数据”**。
    * 它**污染**了你的数据集。
    * 当你（或你的客户）去数据库里查询“工序A”的“平均节拍”时，这个 54,000 秒的“幽灵数据”会把平均值从（假设）5.0秒，**直接拉高到几百秒**。
    * 你的整个“寻找痛点”的分析，在这一刻就**完全失效**了。
